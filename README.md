# Optimizing Machine Learning with CUDA: A Comparative Study with PyTorch 

## üìù [A brief summarization poster](https://drive.google.com/file/d/1-79boy7_EZHLIIbIy23dW9GVcFYegx6w/view?usp=sharing)

## Research Focus

This project aims to compare the performance of a PyTorch machine learning model and a CUDA machine learning model generated using Large Language Models (LLMs). The primary goal is to evaluate the optimization capabilities of LLMs in generating CUDA code for machine learning tasks, identify any limitations, and determine areas for improvement. Additionally, this research seeks to provide guidance on framework selection for different ML tasks based on the findings.

## Recent Work and Updates (Fall 2024)
- Explored optimization techniques for minimizing synchronization overhead, applying these methods to compare performance between PyTorch and CUDA models.
- Integrated GPU-accelerated libraries, such as cuML from the RAPIDS suite, to extend the comparison with PyTorch, focusing on performance gains in various machine learning tasks.

## Tools and Methods

- **Programming Languages**: Python, NVIDIA CUDA
- **Machine Learning Framework**: PyTorch and CUDA ML models from scratch
- **Large Language Models (LLMs)**: ChatGPT4.0 (for generating CUDA code)
- **Profiling Tools**: 
  - *NVIDIA Nsight Systems*: For comprehensive profiling and system-level analysis of CUDA applications.
  - *NVIDIA Nsight Compute*: For detailed kernel profiling and optimization analysis in CUDA.
  - *Perfetto and PyTorch Profiler*: For profiling and analyzing PyTorch models, focusing on performance metrics such as execution time and memory usage.
- **Hardware**: 
  - *NVIDIA RTX 2080 Ti GPUs*: Utilized for running CUDA and PyTorch models.
  - *UVA GPU servers*: The primary computing resource for running and profiling experiments.
- **Visualization**:
  - *Matplotlib*: Used for creating performance comparison charts and visualizations to clearly display the results.


## Phase 1: Learning CUDA and Optimization Techniques

### Objective: 
Learn the fundamentals of CUDA programming, implement simple CUDA applications, and use profiling tools to analyze and optimize these applications.

### Activities:
- **Vector Addition Example**:
  - Implemented vector addition in both Python and CUDA.
  - Compared the performance of the Python vs. CUDA implementations to demonstrate the speedup achieved through GPU acceleration.
  - Applied optimization techniques (e.g., memory coalescing, kernel tuning) to further enhance the CUDA implementation.
  
- **Profiling and Visualization**:
  - Used NVIDIA Nsight tools to profile the CUDA implementation.
  - Created visualizations showing the impact of various optimizations on execution time and resource utilization.


## Phase 2: Optimize CUDA generated code from LLMs

### Objective:
To evaluate and enhance the performance of CUDA code generated by Large Language Models (LLMs) like ChatGPT. This phase focuses on identifying and applying optimization techniques to the LLM-generated CUDA code, aiming to improve its execution efficiency and close the gap with manually optimized CUDA code.

### Activities:
- **Code Generation**:
  - Utilized ChatGPT to generate CUDA code for basic machine learning tasks, such as vector addition, matrix multiplication, and simple neural networks.
  - Assessed the initial performance of the LLM-generated code, focusing on execution time, memory usage, and kernel efficiency.
  
- **Optimization Identification**:
  - Analyzed the generated code to identify potential inefficiencies, such as suboptimal memory access patterns, lack of kernel fusion, and synchronization overhead.
  - Reviewed and documented best practices in CUDA programming that were either missing or inadequately implemented in the LLM-generated code.

- **Manual Optimization**:
  - Applied advanced CUDA optimization techniques, including:
    - **Memory Coalescing**: Ensured that global memory accesses are coalesced to improve memory bandwidth utilization.
    - **Kernel Fusion**: Combined multiple kernels into a single kernel to reduce kernel launch overhead.
    - **Shared Memory Usage**: Leveraged shared memory to minimize global memory accesses, reducing latency.
    - **Concurrency Management**: Improved the use of CUDA streams to enable overlapping of memory transfers and kernel execution.
  - Refined the LLM-generated code based on these techniques and compared the performance against the original unoptimized version.

- **Performance Profiling**:
  - Used Nsight Systems and Nsight Compute to profile the optimized LLM-generated code.
  - Measured and documented improvements in execution time, memory usage, and GPU utilization.

- **Comparative Analysis**:
  - Compared the performance of the optimized LLM-generated CUDA code with manually written and optimized CUDA code.
  - Evaluated the effectiveness of LLMs in generating code that can be easily optimized, identifying strengths and weaknesses.

- **Result Visualization**:
  - Created visualizations to illustrate the performance improvements achieved through manual optimizations.
  - Highlighted areas where LLM-generated code performed well and where further improvements were necessary.

### Outcome:
This phase aimed to demonstrate the potential of LLMs in generating CUDA code that, with targeted optimizations, can achieve performance close to manually optimized implementations. The insights gained from this phase will inform the development of more sophisticated prompts and techniques for guiding LLMs in future code generation tasks.

## Phase 3: Performance Comparison for PyTorch and CUDA Simple ML Models

### Objective:
To assess the performance differences between PyTorch and CUDA implementations of simple machine learning models. 

### Activities:
- **Model Implementation**: Developed basic ML models (e.g., linear regression, single-layer neural networks) in both PyTorch and CUDA.
- **Performance Profiling**: Employed Nsight Systems and Nsight Compute to profile execution time, memory usage, and GPU utilization for both implementations.
- **Optimization Analysis**: Use CUDA-specific optimizations code in Phase 2 to compare the performance gains to those achieved with PyTorch.
- **Benchmarking**: Conducted benchmarking by varying input sizes, batch sizes, and data types to assess how each framework handles different scenarios.
- **Result Visualization**: Generated visual comparisons of training time, inference time, accuracy, and other key performance metrics to highlight the strengths and weaknesses of each approach.

## Future Work

- **Scalability**: Extend the comparison to more complex models and larger datasets.
- **Explore Benchmark**: Implement more advanced tasks like image classification and GANs to broaden the scope of comparison.
- **Enhance CUDA Techniques**: Apply more advanced CUDA optimization strategies for better performance.
- **Advanced LLM Utilization**: Investigate how to better guide LLMs in generating highly optimized CUDA code.
- **Extended Comparisons**: Consider comparing CUDA models with other machine learning frameworks like TensorFlow.

## Acknowledgments

- Special thanks to Professor Adwait Jog for guidance and support.
- Acknowledgment to the Department of Computer Science at the University of Virginia for providing the necessary resources and GPU servers.
